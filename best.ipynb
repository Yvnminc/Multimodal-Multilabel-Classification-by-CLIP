{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-01T05:51:22.610324Z",
     "iopub.status.busy": "2023-05-01T05:51:22.609561Z",
     "iopub.status.idle": "2023-05-01T05:51:22.823435Z",
     "shell.execute_reply": "2023-05-01T05:51:22.822401Z",
     "shell.execute_reply.started": "2023-05-01T05:51:22.610278Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "test_image_features = torch.load(\"features/test_image_features_vitL.pt\", map_location = torch.device(dev))\n",
    "test_text_feature = torch.load(\"features/test_text_feature_vitL.pt\", map_location = torch.device(dev))\n",
    "all_image_features = torch.load(\"features/all_image_features_vitL.pt\", map_location = torch.device(dev))\n",
    "all_text_feature = torch.load(\"features/all_text_feature_vitL.pt\", map_location = torch.device(dev))\n",
    "label_onehot_tensor = torch.load(\"features/label_onehot_tensor.pt\", map_location = torch.device(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:51:22.826083Z",
     "iopub.status.busy": "2023-05-01T05:51:22.825618Z",
     "iopub.status.idle": "2023-05-01T05:51:22.833769Z",
     "shell.execute_reply": "2023-05-01T05:51:22.832765Z",
     "shell.execute_reply.started": "2023-05-01T05:51:22.826044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 768])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:51:22.835862Z",
     "iopub.status.busy": "2023-05-01T05:51:22.835097Z",
     "iopub.status.idle": "2023-05-01T05:51:22.843484Z",
     "shell.execute_reply": "2023-05-01T05:51:22.842316Z",
     "shell.execute_reply.started": "2023-05-01T05:51:22.835823Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_weight_decay(model, weight_decay=1e-4, skip_list=()):\n",
    "    decay = []\n",
    "    no_decay = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue  # frozen weights\n",
    "        if len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list:\n",
    "            no_decay.append(param)\n",
    "        else:\n",
    "            decay.append(param)\n",
    "    return [\n",
    "        {'params': no_decay, 'weight_decay': 0.},\n",
    "        {'params': decay, 'weight_decay': weight_decay}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:51:22.846727Z",
     "iopub.status.busy": "2023-05-01T05:51:22.846011Z",
     "iopub.status.idle": "2023-05-01T05:51:22.865251Z",
     "shell.execute_reply": "2023-05-01T05:51:22.864278Z",
     "shell.execute_reply.started": "2023-05-01T05:51:22.846690Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AsymmetricLoss(nn.Module):\n",
    "    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=True):\n",
    "        super(AsymmetricLoss, self).__init__()\n",
    "\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.clip = clip\n",
    "        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: input logits\n",
    "        y: targets (multi-label binarized vector)\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculating Probabilities\n",
    "        \n",
    "        xs_pos = x\n",
    "        xs_neg = 1 - x\n",
    "\n",
    "        # Asymmetric Clipping\n",
    "        if self.clip is not None and self.clip > 0:\n",
    "            xs_neg = (xs_neg + self.clip).clamp(max=1)\n",
    "\n",
    "        # Basic CE calculation\n",
    "        los_pos = y * torch.log(xs_pos.clamp(min=self.eps))\n",
    "        los_neg = (1 - y) * torch.log(xs_neg.clamp(min=self.eps))\n",
    "        loss = los_pos + los_neg\n",
    "\n",
    "        # Asymmetric Focusing\n",
    "        if self.gamma_neg > 0 or self.gamma_pos > 0:\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(False)\n",
    "            pt0 = xs_pos * y\n",
    "            pt1 = xs_neg * (1 - y)  # pt = p if t > 0 else 1-p\n",
    "            pt = pt0 + pt1\n",
    "            one_sided_gamma = self.gamma_pos * y + self.gamma_neg * (1 - y)\n",
    "            one_sided_w = torch.pow(1 - pt, one_sided_gamma)\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(True)\n",
    "            loss *= one_sided_w\n",
    "\n",
    "        return -loss.sum()\n",
    "\n",
    "\n",
    "class AsymmetricLossOptimized(nn.Module):\n",
    "    ''' Notice - optimized version, minimizes memory allocation and gpu uploading,\n",
    "    favors inplace operations'''\n",
    "\n",
    "    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=False):\n",
    "        super(AsymmetricLossOptimized, self).__init__()\n",
    "\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.clip = clip\n",
    "        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n",
    "        self.eps = eps\n",
    "\n",
    "        # prevent memory allocation and gpu uploading every iteration, and encourages inplace operations\n",
    "        self.targets = self.anti_targets = self.xs_pos = self.xs_neg = self.asymmetric_w = self.loss = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: input logits\n",
    "        y: targets (multi-label binarized vector)\n",
    "        \"\"\"\n",
    "\n",
    "        self.targets = y\n",
    "        self.anti_targets = 1 - y\n",
    "\n",
    "        # Calculating Probabilities\n",
    "        self.xs_pos = torch.sigmoid(x)\n",
    "        self.xs_neg = 1.0 - self.xs_pos\n",
    "\n",
    "        # Asymmetric Clipping\n",
    "        if self.clip is not None and self.clip > 0:\n",
    "            self.xs_neg.add_(self.clip).clamp_(max=1)\n",
    "\n",
    "        # Basic CE calculation\n",
    "        self.loss = self.targets * torch.log(self.xs_pos.clamp(min=self.eps))\n",
    "        self.loss.add_(self.anti_targets * torch.log(self.xs_neg.clamp(min=self.eps)))\n",
    "\n",
    "        # Asymmetric Focusing\n",
    "        if self.gamma_neg > 0 or self.gamma_pos > 0:\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(False)\n",
    "            self.xs_pos = self.xs_pos * self.targets\n",
    "            self.xs_neg = self.xs_neg * self.anti_targets\n",
    "            self.asymmetric_w = torch.pow(1 - self.xs_pos - self.xs_neg,\n",
    "                                          self.gamma_pos * self.targets + self.gamma_neg * self.anti_targets)\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(True)\n",
    "            self.loss *= self.asymmetric_w\n",
    "\n",
    "        return -self.loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T05:51:22.867113Z",
     "iopub.status.busy": "2023-05-01T05:51:22.866514Z",
     "iopub.status.idle": "2023-05-01T05:51:22.879780Z",
     "shell.execute_reply": "2023-05-01T05:51:22.879006Z",
     "shell.execute_reply.started": "2023-05-01T05:51:22.867076Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import F1Score\n",
    "from torch import optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "def Trainer(model, Data, epochs, epoch_step_1, epoch_step_2, lr = 1e-3):\n",
    "    torch.manual_seed(5329)\n",
    "    #train_data = DataLoader(TensorDataset(Data[:25000], label_onehot_tensor[:25000]), batch_size=25000, shuffle = True)\n",
    "    #val_data = DataLoader(TensorDataset(Data[25000:], label_onehot_tensor[25000:].to(torch.int32)), batch_size=5000, shuffle = False)\n",
    "    \n",
    "    # Change here to switch to the best setting\n",
    "    train_data = DataLoader(TensorDataset(Data, label_onehot_tensor), batch_size=30000, shuffle = True)\n",
    "    \n",
    "    model = model.to(dev)\n",
    " \n",
    "    weight_decay = 2e-4\n",
    "    criterion = AsymmetricLoss(gamma_neg=0, gamma_pos=0, clip=0, disable_torch_grad_focal_loss=True)\n",
    "    parameters = add_weight_decay(model, weight_decay)\n",
    "    opti = optim.Adam(params=parameters, lr=lr, weight_decay=0)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(opti, milestones=[epoch_step_1,epoch_step_2], gamma = 0.1)\n",
    "    f1 = F1Score(task=\"multilabel\", num_labels = 18).to(dev)\n",
    "\n",
    "    epoch = epochs\n",
    "    loss_list = []\n",
    "    f1_list = []\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for epoch in tqdm(range(epoch), colour = 'GREEN'):\n",
    "        for data, label in train_data:   \n",
    "            data, label = data.to(dev), label.to(dev)\n",
    "\n",
    "            with autocast():  # mixed precision\n",
    "                output = model(data).float() \n",
    "\n",
    "            loss = criterion(output, label)\n",
    "            model.zero_grad()\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opti)\n",
    "            scaler.update()\n",
    "            \n",
    "        loss_list.append(loss)\n",
    "        \n",
    "        # Comment the code below if you want to switch to the best settings (i.e., no validation data)\n",
    "#         if epoch % 10 == 0:\n",
    "#             with torch.autograd.no_grad():\n",
    "#                 for data_val, label_val in val_data:\n",
    "#                     data_val, label_val = data_val.to(dev), label_val.to(dev)\n",
    "#                     predict = model(data_val)\n",
    "#                     f1_score = f1(predict, label_val)\n",
    "#                 print('Validation F1 in epoch{} : {:.4f}'.format(epoch, f1_score))\n",
    "#             f1_list.append(f1_score)\n",
    "    \n",
    "    return model, loss_list, f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T06:38:15.291189Z",
     "iopub.status.busy": "2023-05-01T06:38:15.290007Z",
     "iopub.status.idle": "2023-05-01T06:38:15.300838Z",
     "shell.execute_reply": "2023-05-01T06:38:15.299745Z",
     "shell.execute_reply.started": "2023-05-01T06:38:15.291122Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class FEATURE_EXTRACTOR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(768, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 512)\n",
    "        self.fc3 = nn.Linear(512, 18)\n",
    "        self.dropout = nn.Dropout(p = 0.6)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        tensor = F.gelu(self.fc1(inputs))\n",
    "        tensor = self.dropout(tensor)\n",
    "        tensor = F.gelu(self.fc2(tensor))\n",
    "        tensor = self.dropout(tensor)\n",
    "        tensor = torch.sigmoid(self.fc3(tensor))\n",
    "        return tensor\n",
    "\n",
    "class DECISION_MODEL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(18, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 18)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        tensor = F.gelu(self.fc1(inputs))\n",
    "        tensor = F.gelu(self.fc2(tensor))\n",
    "        tensor = torch.sigmoid(self.fc3(tensor))\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m████████████████████████████████████████████████████████████████████████████████\u001b[0m| 300/300 [01:35<00:00,  3.13it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "Net, loss_list, f1_list = Trainer(FEATURE_EXTRACTOR(), all_image_features, 300, 200, 250)\n",
    "model_dir = './model/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "torch.save(Net.state_dict(), os.path.join(model_dir, 'image_model.pth'))\n",
    "Net.eval()\n",
    "with torch.autograd.no_grad():\n",
    "    img_train = Net(all_image_features.to(dev))\n",
    "    img_test = Net(test_image_features.to(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T06:40:46.129649Z",
     "iopub.status.busy": "2023-05-01T06:40:46.129013Z",
     "iopub.status.idle": "2023-05-01T06:43:12.937146Z",
     "shell.execute_reply": "2023-05-01T06:43:12.936093Z",
     "shell.execute_reply.started": "2023-05-01T06:40:46.129608Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m████████████████████████████████████████████████████████████████████████████████\u001b[0m| 300/300 [01:34<00:00,  3.19it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Net, loss_list, f1_list = Trainer(FEATURE_EXTRACTOR(), all_text_feature, 300, 200, 250)\n",
    "model_dir = './model/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "torch.save(Net.state_dict(), os.path.join(model_dir, 'text_model.pth'))\n",
    "Net.eval()\n",
    "with torch.autograd.no_grad():\n",
    "    txt_train = Net(all_text_feature.to(dev))\n",
    "    txt_test = Net(test_text_feature.to(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T06:43:12.939468Z",
     "iopub.status.busy": "2023-05-01T06:43:12.938803Z",
     "iopub.status.idle": "2023-05-01T06:45:15.748503Z",
     "shell.execute_reply": "2023-05-01T06:45:15.747403Z",
     "shell.execute_reply.started": "2023-05-01T06:43:12.939426Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m████████████████████████████████████████████████████████████████████████████████\u001b[0m| 300/300 [01:32<00:00,  3.25it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sum_train = img_train+txt_train\n",
    "sum_test = img_test+txt_test\n",
    "Net, loss_list, f1_list  = Trainer(DECISION_MODEL(), sum_train, 300, 200, 250)\n",
    "model_dir = './model/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "torch.save(Net.state_dict(), os.path.join(model_dir, 'final_model.pth'))\n",
    "Net.eval()\n",
    "with torch.autograd.no_grad():\n",
    "    final = Net(sum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T06:45:31.806624Z",
     "iopub.status.busy": "2023-05-01T06:45:31.805902Z",
     "iopub.status.idle": "2023-05-01T06:45:39.761943Z",
     "shell.execute_reply": "2023-05-01T06:45:39.760925Z",
     "shell.execute_reply.started": "2023-05-01T06:45:31.806584Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y_proba = final.cpu().numpy()\n",
    "\n",
    "resl = []\n",
    "for i in y_proba:\n",
    "    a = [x+1 for x in range(len(i)) if i[x] > 0.5]\n",
    "    for j in range(len(a)):\n",
    "        if a[j] >=12:\n",
    "            a[j] = a[j]+1\n",
    "    resl.append(a)\n",
    "test_pred = []\n",
    "for lis in resl:\n",
    "    a = [str(i) for i in lis]\n",
    "    test_pred.append(\" \".join(a))\n",
    "\n",
    "# make a csv file\n",
    "df = pd.DataFrame(columns=[\"ImageID\", \"Labels\"])\n",
    "\n",
    "# Creating the Second Dataframe using dictionary\n",
    "for index, value in enumerate(test_pred):\n",
    "    df_temp = pd.DataFrame({\"ImageID\":\"{}.jpg\".format(30000+index), \"Labels\":\" \".join([str(i) for i in [value]])}, index=[0])\n",
    "    \n",
    "    # for appending df_temp at the end of df\n",
    "    df = pd.concat([df, df_temp], ignore_index=True)\n",
    "\n",
    "df.to_csv(\"Predicted_labels.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T06:45:45.948076Z",
     "iopub.status.busy": "2023-05-01T06:45:45.947142Z",
     "iopub.status.idle": "2023-05-01T06:45:45.960734Z",
     "shell.execute_reply": "2023-05-01T06:45:45.959545Z",
     "shell.execute_reply.started": "2023-05-01T06:45:45.948023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>39995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>39996.jpg</td>\n",
       "      <td>3 4 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>39997.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>39998.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>39999.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ImageID Labels\n",
       "0     30000.jpg      1\n",
       "1     30001.jpg      1\n",
       "2     30002.jpg      1\n",
       "3     30003.jpg      1\n",
       "4     30004.jpg      1\n",
       "...         ...    ...\n",
       "9995  39995.jpg      1\n",
       "9996  39996.jpg  3 4 8\n",
       "9997  39997.jpg      1\n",
       "9998  39998.jpg      1\n",
       "9999  39999.jpg      1\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
