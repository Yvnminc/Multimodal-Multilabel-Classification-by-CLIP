{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cbe33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code to download file into Colaboratory:\n",
    "# !pip install -U -q PyDrive > /dev/null\n",
    "# !pip install torchmetrics > /dev/null\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# import torch\n",
    "# dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "# # Authenticate and create the PyDrive client.\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)\n",
    "\n",
    "# #get the data from the drive\n",
    "# def get_feature(model = \"ViT-L/14@336px\"):\n",
    "#   id = '11yXddz5j-IDcH77wkMF7dW2JctRv7YN6'\n",
    "#   size = \"B\"\n",
    "\n",
    "#   if model == 'ViT-L/14@336px':\n",
    "#     id = '1P6CgrgiIACjnhtHsUwdY8qjZ-E3Vx_0x'\n",
    "#     size = \"L336\"\n",
    "#   elif model == 'ViT-L/14':\n",
    "#     id = '1DG4J-YF57ZsfXTzwg5EFfkzUmUFfr82h'\n",
    "#     size = \"L\"\n",
    "#   elif model == 'ViT-B/32':\n",
    "#     id = '11yXddz5j-IDcH77wkMF7dW2JctRv7YN6'\n",
    "#     size = \"B\"\n",
    "\n",
    "#   downloaded = drive.CreateFile({'id':id}) \n",
    "#   downloaded.GetContentFile('clip_features.zip')\n",
    "\n",
    "#   #get the data from the drive\n",
    "#   id = '1b-ujWaLM_jOzlRMbXVb9T-3oEibKQW1r'\n",
    "#   downloaded = drive.CreateFile({'id':id}) \n",
    "#   downloaded.GetContentFile('label_onehot_tensor.pt')\n",
    "\n",
    "#   !unzip clip_features.zip > /dev/null\n",
    "\n",
    "#   test_image_features = torch.load(f\"test_image_features_vit{size}.pt\")\n",
    "#   test_text_feature = torch.load(f\"test_text_feature_vit{size}.pt\")\n",
    "#   all_image_features = torch.load(f\"all_image_features_vit{size}.pt\")\n",
    "#   all_text_feature = torch.load(f\"all_text_feature_vit{size}.pt\")\n",
    "#   label_onehot_tensor = torch.load(f\"label_onehot_tensor.pt\")\n",
    "\n",
    "#   return all_image_features, all_text_feature, test_image_features, test_text_feature, label_onehot_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e3b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_image_features, all_text_feature, test_image_features, test_text_feature, label_onehot_tensor = get_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbe06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# test_image_features = torch.load(\"test_image_features_vitL.pt\", map_location = torch.device(dev))\n",
    "# test_text_feature = torch.load(\"test_text_feature_vitL.pt\", map_location = torch.device(dev))\n",
    "# all_image_features = torch.load(\"all_image_features_vitL.pt\", map_location = torch.device(dev))\n",
    "# all_text_feature = torch.load(\"all_text_feature_vitL.pt\", map_location = torch.device(dev))\n",
    "# label_onehot_tensor = torch.load(\"label_onehot_tensor.pt\", map_location = torch.device(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90083f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "test_image_features = torch.load(\"../features/test_image_features_vitL.pt\", map_location = torch.device(dev))\n",
    "test_text_feature = torch.load(\"../features/test_text_feature_vitL.pt\", map_location = torch.device(dev))\n",
    "all_image_features = torch.load(\"../features/all_image_features_vitL.pt\", map_location = torch.device(dev))\n",
    "all_text_feature = torch.load(\"../features/all_text_feature_vitL.pt\", map_location = torch.device(dev))\n",
    "label_onehot_tensor = torch.load(\"../features/label_onehot_tensor.pt\", map_location = torch.device(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce3aae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d594fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weight_decay(model, weight_decay=1e-4, skip_list=()):\n",
    "    decay = []\n",
    "    no_decay = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue  # frozen weights\n",
    "        if len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list:\n",
    "            no_decay.append(param)\n",
    "        else:\n",
    "            decay.append(param)\n",
    "    return [\n",
    "        {'params': no_decay, 'weight_decay': 0.},\n",
    "        {'params': decay, 'weight_decay': weight_decay}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49166183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AsymmetricLoss(nn.Module):\n",
    "    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=True):\n",
    "        super(AsymmetricLoss, self).__init__()\n",
    "\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.clip = clip\n",
    "        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: input logits\n",
    "        y: targets (multi-label binarized vector)\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculating Probabilities\n",
    "        \n",
    "        xs_pos = x\n",
    "        xs_neg = 1 - x\n",
    "\n",
    "        # Asymmetric Clipping\n",
    "        if self.clip is not None and self.clip > 0:\n",
    "            xs_neg = (xs_neg + self.clip).clamp(max=1)\n",
    "\n",
    "        # Basic CE calculation\n",
    "        los_pos = y * torch.log(xs_pos.clamp(min=self.eps))\n",
    "        los_neg = (1 - y) * torch.log(xs_neg.clamp(min=self.eps))\n",
    "        loss = los_pos + los_neg\n",
    "\n",
    "        # Asymmetric Focusing\n",
    "        if self.gamma_neg > 0 or self.gamma_pos > 0:\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(False)\n",
    "            pt0 = xs_pos * y\n",
    "            pt1 = xs_neg * (1 - y)  # pt = p if t > 0 else 1-p\n",
    "            pt = pt0 + pt1\n",
    "            one_sided_gamma = self.gamma_pos * y + self.gamma_neg * (1 - y)\n",
    "            one_sided_w = torch.pow(1 - pt, one_sided_gamma)\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(True)\n",
    "            loss *= one_sided_w\n",
    "\n",
    "        return -loss.sum()\n",
    "\n",
    "\n",
    "class AsymmetricLossOptimized(nn.Module):\n",
    "    ''' Notice - optimized version, minimizes memory allocation and gpu uploading,\n",
    "    favors inplace operations'''\n",
    "\n",
    "    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=False):\n",
    "        super(AsymmetricLossOptimized, self).__init__()\n",
    "\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.clip = clip\n",
    "        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n",
    "        self.eps = eps\n",
    "        # prevent memory allocation and gpu uploading every iteration, and encourages inplace operations\n",
    "        self.targets = self.anti_targets = self.xs_pos = self.xs_neg = self.asymmetric_w = self.loss = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: input logits\n",
    "        y: targets (multi-label binarized vector)\n",
    "        \"\"\"\n",
    "\n",
    "        self.targets = y\n",
    "        self.anti_targets = 1 - y\n",
    "\n",
    "        # Calculating Probabilities\n",
    "        self.xs_pos = torch.sigmoid(x)\n",
    "        self.xs_neg = 1.0 - self.xs_pos\n",
    "\n",
    "        # Asymmetric Clipping\n",
    "        if self.clip is not None and self.clip > 0:\n",
    "            self.xs_neg.add_(self.clip).clamp_(max=1)\n",
    "\n",
    "        # Basic CE calculation\n",
    "        self.loss = self.targets * torch.log(self.xs_pos.clamp(min=self.eps))\n",
    "        self.loss.add_(self.anti_targets * torch.log(self.xs_neg.clamp(min=self.eps)))\n",
    "        \n",
    "        # Asymmetric Focusing\n",
    "        if self.gamma_neg > 0 or self.gamma_pos > 0:\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(False)\n",
    "            self.xs_pos = self.xs_pos * self.targets\n",
    "            self.xs_neg = self.xs_neg * self.anti_targets\n",
    "            self.asymmetric_w = torch.pow(1 - self.xs_pos - self.xs_neg,\n",
    "                                          self.gamma_pos * self.targets + self.gamma_neg * self.anti_targets)\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(True)\n",
    "            self.loss *= self.asymmetric_w\n",
    "\n",
    "        return -self.loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d7b273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import F1Score\n",
    "from torch import optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "def Trainer(model, Data, epochs, epoch_step_1, epoch_step_2, lr = 1e-3):\n",
    "    torch.manual_seed(5329)\n",
    "    train_data = DataLoader(TensorDataset(Data[:25000], label_onehot_tensor[:25000]), batch_size=25000, shuffle = True)\n",
    "    val_data = DataLoader(TensorDataset(Data[25000:], label_onehot_tensor[25000:].to(torch.int32)), batch_size=5000, shuffle = False)\n",
    "    \n",
    "    # Change here to switch to the best setting\n",
    "    # train_data = DataLoader(TensorDataset(Data, label_onehot_tensor), batch_size=30000, shuffle = True)\n",
    "    \n",
    "    model = model.to(dev)\n",
    " \n",
    "    weight_decay = 2e-4\n",
    "    criterion = AsymmetricLoss(gamma_neg=0, gamma_pos=0, clip=0, disable_torch_grad_focal_loss=True)\n",
    "    parameters = add_weight_decay(model, weight_decay)\n",
    "    opti = optim.Adam(params=parameters, lr=lr, weight_decay=0)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(opti, milestones=[epoch_step_1,epoch_step_2], gamma = 0.1)\n",
    "    f1 = F1Score(task=\"multilabel\", num_labels = 18).to(dev)\n",
    "\n",
    "    epoch = epochs\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    f1_list = []\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    for epoch in tqdm(range(epoch), colour = 'GREEN'):\n",
    "        for data, label in train_data:   \n",
    "            data, label = data.to(dev), label.to(dev)\n",
    "\n",
    "            with autocast():  # mixed precision\n",
    "                output = model(data).float() \n",
    "\n",
    "            loss = criterion(output, label)\n",
    "            model.zero_grad()\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opti)\n",
    "            scaler.update()\n",
    "            \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        with torch.autograd.no_grad():\n",
    "            for data_val, label_val in val_data:\n",
    "                data_val, label_val = data_val.to(dev), label_val.to(dev)\n",
    "                predict = model(data_val)\n",
    "                f1_score = f1(predict, label_val)\n",
    "                v_loss = criterion(predict, label_val)\n",
    "            val_loss.append(v_loss.item())\n",
    "            f1_list.append(f1_score.item())\n",
    "        \n",
    "        # Comment the code below if you want to switch to the best settings (i.e., no validation data)\n",
    "        if epoch % 10 == 0:\n",
    "            print('Validation F1 in epoch{} : {:.4f}'.format(epoch, f1_score.item()))\n",
    "            print('Validation loss in epoch{} : {:.4f}'.format(epoch, v_loss.item()))\n",
    "    \n",
    "    return model, train_loss, val_loss, f1_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd2ac3",
   "metadata": {},
   "source": [
    "## Experiments on Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff1d2a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class FEATURE_EXTRACTOR(nn.Module):\n",
    "    def __init__(self, act:str='gelu'):\n",
    "        super().__init__()\n",
    "        self.act = act\n",
    "        self.fc1 = nn.Linear(768, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 512)\n",
    "        self.fc3 = nn.Linear(512, 18)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.act == 'gelu':\n",
    "            tensor = F.gelu(self.fc1(inputs))\n",
    "            tensor = self.dropout(tensor)\n",
    "            tensor = F.gelu(self.fc2(tensor))\n",
    "        elif self.act == 'relu':\n",
    "            tensor = F.relu(self.fc1(inputs))\n",
    "            tensor = self.dropout(tensor)\n",
    "            tensor = F.relu(self.fc2(tensor))\n",
    "        elif self.act == 'leaky_relu':\n",
    "            tensor = F.leaky_relu(self.fc1(inputs))\n",
    "            tensor = self.dropout(tensor)\n",
    "            tensor = F.leaky_relu(self.fc2(tensor))\n",
    "        tensor = self.dropout(tensor)\n",
    "        tensor = torch.sigmoid(self.fc3(tensor))\n",
    "        return tensor\n",
    "\n",
    "class DECISION_MODEL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(18, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 18)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        tensor = F.gelu(self.fc1(inputs))\n",
    "        tensor = F.gelu(self.fc2(tensor))\n",
    "        tensor = torch.sigmoid(self.fc3(tensor))\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac0aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[32m▎                                                                                 \u001b[0m| 1/300 [00:00<04:51,  1.03it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 in epoch0 : 0.1097\n",
      "Validation loss in epoch0 : 62664.8281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|\u001b[32m██▉                                                                              \u001b[0m| 11/300 [00:03<01:19,  3.65it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 in epoch10 : 0.1108\n",
      "Validation loss in epoch10 : 62688.5742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|\u001b[32m███▊                                                                             \u001b[0m| 14/300 [00:04<01:18,  3.66it/s]\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "activation_function = ['gelu','relu','leaky_relu']\n",
    "mean_list = []\n",
    "std_list = []\n",
    "val_loss = []\n",
    "train_loss = []\n",
    "for i in range(len(activation_function)):\n",
    "    f1_list = []\n",
    "    for j in range(3):\n",
    "        Net, train_image_loss, val_image_loss, f1_image_list = Trainer(FEATURE_EXTRACTOR(act=activation_function[i]), \n",
    "                                                                       all_image_features, 300, 200, 250)\n",
    "        Net.eval()\n",
    "        with torch.autograd.no_grad():\n",
    "            img_train = Net(all_image_features.to(dev))\n",
    "            img_test = Net(test_image_features.to(dev))\n",
    "\n",
    "        Net, train_text_loss, val_text_loss, f1_text_list = Trainer(FEATURE_EXTRACTOR(act=activation_function[i]), \n",
    "                                                                    all_text_feature, 300, 200, 250)\n",
    "        Net.eval()\n",
    "        with torch.autograd.no_grad():\n",
    "            txt_train = Net(all_text_feature.to(dev))\n",
    "            txt_test = Net(test_text_feature.to(dev))\n",
    "\n",
    "        sum_train = img_train + txt_train\n",
    "        sum_test = img_test + txt_test\n",
    "        Net, train_sum_loss, val_sum_loss, f1_sum_list = Trainer(DECISION_MODEL(), sum_train, 300, 200, 250)\n",
    "        Net.eval()\n",
    "        \n",
    "        f1_list.append(f1_sum_list[-1])\n",
    "    \n",
    "    mean_list.append(np.mean(f1_list))\n",
    "    std_list.append(np.std(f1_list))\n",
    "    \n",
    "    train_loss.append(train_sum_loss)\n",
    "    val_loss.append(val_sum_loss)\n",
    "    \n",
    "print(\"Mean: \", mean_list)\n",
    "print('Std: ', std_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(val_loss[0], label='GeLU')\n",
    "plt.plot(val_loss[1], label='ReLU')\n",
    "plt.plot(val_loss[2], label='Leaky ReLU')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "#plt.savefig('mlploss.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
